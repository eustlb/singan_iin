{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the realm of machine learning, the ability to construct extensive image datasets and access unprecedented computational resources has facilitated the rise of deep learning techniques, notably revolutionizing the landscape of image generation. Specifically, Ian Goodfellow and his colleagues introduced Generative Adversarial Networks (GANs) in 2014, which have since emerged as a fundamental cornerstone in the field of computer vision.\n",
    "\n",
    "At their core, GANs are composed of two neural networks – a generator and a discriminator – engaged in a dynamic adversarial training process. The generator strives to create synthetic data that is indistinguishable from real data, while the discriminator aims to accurately classify whether the given data is real or generated (see image below). \n",
    "\n",
    "<img src=\"figures/gans.png\" style=\"height: 500px;\"/>\n",
    "\\\\\n",
    "\n",
    "[source](https://www.analyticsvidhya.com/blog/2021/04/lets-talk-about-gans/)\n",
    "\n",
    "The main idea is that the generator tries to fool the discriminator by showing it fake training data samples and the discriminator tries to be as clever as possible. To do so, it learns the probability distribution of our training data. Training aims to improve both of those neural nets that have competitive objective, hence the term *adversarial*.\n",
    "\n",
    "The discriminator is a simple binary classifier, so it's loss is a simple binary cross-entropy.\n",
    "By writing:\n",
    "- $z$ the input noise\n",
    "- $x$ a training sample\n",
    "- $G(z)$ the image outputted by the generator\n",
    "- $D(x)$ the probability of the image being real outputted by the discriminator\n",
    "\n",
    "We get the loss, that will have to be maximized when training the discriminator :\n",
    "$$\n",
    "log(D(x)) + log(1-D(G(z)))\n",
    "$$\n",
    "Yet, the generator objective is to fool the discriminator: it tries to minimize $log(1-D(G(z)))$\n",
    "This way, we get the adversarial objectif, encompassing adversarial training of our generator and discriminator:\n",
    "$$\n",
    "\\operatorname*{min}_{G}\\operatorname*{max}_{D}V(D,G)=\\mathbb{E}_{x\\sim p_{\\mathrm{data}}}[\\log D(x)]+\\mathbb{E}_{z\\sim p_{z}}[\\log(1-D(G(z)))].\n",
    "$$\n",
    "In practice, we first train the discriminator by ascending gradient and train the generator every k-steps by descending gradient. Moreover, this training of the generator in actually rather done by maximizing $log(D(G(z)))$, providing better gradients in early training when  $log(1 - D(G(z)))$ saturates because of poor quality of $G(z)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: ./SinGAN: No such file or directory\n",
      "Clonage dans 'SinGAN'...\n",
      "remote: Enumerating objects: 55, done.\u001b[K\n",
      "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
      "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
      "remote: Total 55 (delta 9), reused 52 (delta 6), pack-reused 0\u001b[K\n",
      "Réception d'objets: 100% (55/55), 4.53 Mio | 24.57 Mio/s, fait.\n",
      "Résolution des deltas: 100% (9/9), fait.\n"
     ]
    }
   ],
   "source": [
    "# load github repo\n",
    "try:\n",
    "    !rm -r ./SinGAN\n",
    "except:\n",
    "    pass\n",
    "get_ipython().system(f\"git clone https://github.com/eustlb/SinGAN.git\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "h-exercice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
